{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3adccf9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 191 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'Testing',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False                # keep order for matching preds to labels\n",
    ").map(lambda x,y: (x/255.0, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db54bdc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "data_dir = 'Testing'\n",
    "filepaths = []\n",
    "labels    = []\n",
    "\n",
    "for label_name, label_value in [('cancer', 1), ('normal', 0)]:\n",
    "    folder = os.path.join(data_dir, label_name)\n",
    "    for fname in os.listdir(folder):\n",
    "        if fname.lower().endswith(('.png','.jpg','.jpeg')):\n",
    "            filepaths.append(os.path.join(folder, fname))\n",
    "            labels.append(label_value)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'filepath': filepaths,\n",
    "    'label': labels\n",
    "})\n",
    "# (Optional) save to CSV\n",
    "df.to_csv('external_labels.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "220e8778",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('external_labels.csv')\n",
    "\n",
    "def load_and_preprocess(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img, channels=3)\n",
    "    # img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    return img, label\n",
    "\n",
    "paths = df['filepath'].values\n",
    "labels = df['label'].values\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "test_ds = test_ds.map(load_and_preprocess).batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1589337f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def load_and_preprocess(path, label):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_image(img, channels=3)\n",
    "    # img = tf.image.resize(img, (224, 224))\n",
    "    # img = tf.cast(img, tf.float32) / 255.0\n",
    "    return img, label\n",
    "\n",
    "paths  = df['filepath'].values\n",
    "labels = df['label'].values\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "test_ds = test_ds.map(load_and_preprocess).batch(BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b269f21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91951\\Downloads\\Lungs-Cancer-Detection-main\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "c:\\Users\\91951\\Downloads\\Lungs-Cancer-Detection-main\\.venv\\Lib\\site-packages\\keras\\src\\optimizers\\base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3b074f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91951\\Downloads\\Lungs-Cancer-Detection-main\\.venv\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(224,224,3)),\n",
    "    # … more convs …\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),   # or Flatten()\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7916632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 191 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "IMG_SIZE   = (224, 224)   # or whatever your model expects\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    'Testing',\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    image_size=IMG_SIZE,     # <-- this resizes every image\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ").map(lambda x, y: (x/255.0, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e26685c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 363ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 367ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 581ms/step\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [191, 31]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m y_pred = np.array(y_pred)\n\u001b[32m     27\u001b[39m y_prob = np.array(y_prob)\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAccuracy:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     30\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPrecision:\u001b[39m\u001b[33m\"\u001b[39m, precision_score(y_true, y_pred))\n\u001b[32m     31\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRecall (sensitivity):\u001b[39m\u001b[33m\"\u001b[39m, recall_score(y_true, y_pred))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91951\\Downloads\\Lungs-Cancer-Detection-main\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91951\\Downloads\\Lungs-Cancer-Detection-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:227\u001b[39m, in \u001b[36maccuracy_score\u001b[39m\u001b[34m(y_true, y_pred, normalize, sample_weight)\u001b[39m\n\u001b[32m    225\u001b[39m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[32m    226\u001b[39m y_true, y_pred = attach_unique(y_true, y_pred)\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m y_type, y_true, y_pred = \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y_type.startswith(\u001b[33m\"\u001b[39m\u001b[33mmultilabel\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91951\\Downloads\\Lungs-Cancer-Detection-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:98\u001b[39m, in \u001b[36m_check_targets\u001b[39m\u001b[34m(y_true, y_pred)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[32m     72\u001b[39m \n\u001b[32m     73\u001b[39m \u001b[33;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     95\u001b[39m \u001b[33;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     97\u001b[39m xp, _ = get_namespace(y_true, y_pred)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m type_true = type_of_target(y_true, input_name=\u001b[33m\"\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    100\u001b[39m type_pred = type_of_target(y_pred, input_name=\u001b[33m\"\u001b[39m\u001b[33my_pred\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\91951\\Downloads\\Lungs-Cancer-Detection-main\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:475\u001b[39m, in \u001b[36mcheck_consistent_length\u001b[39m\u001b[34m(*arrays)\u001b[39m\n\u001b[32m    473\u001b[39m uniques = np.unique(lengths)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m475\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    476\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    477\u001b[39m         % [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[32m    478\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Found input variables with inconsistent numbers of samples: [191, 31]"
     ]
    }
   ],
   "source": [
    "# Quick overall accuracy\n",
    "# loss, acc = model.evaluate(test_ds)\n",
    "# print(f\"Loss: {loss:.4f}, Accuracy: {acc*100:.2f}%\")\n",
    "import sklearn\n",
    "# Or for full metrics:\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "y_true, y_preds, y_prob = [], [], []\n",
    "for imgs, lbls in test_ds:\n",
    "    probs = model.predict(imgs)            # shape (batch, 1)\n",
    "    # Option A: take column 0\n",
    "    pos_probs = probs[:, 0]\n",
    "\n",
    "    # Option B: squeeze into (batch,)\n",
    "    pos_probs = probs.squeeze(axis=1)      # now shape is (batch,)\n",
    "\n",
    "    # then threshold\n",
    "    y_pred = (pos_probs >= 0.5).astype(int)            # shape (batch, 1)\n",
    "\n",
    "    y_true.extend(lbls.numpy().tolist())\n",
    "    y_preds.extend(y_pred)\n",
    "    y_prob.extend(probs)\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n",
    "y_prob = np.array(y_prob)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "print(\"Precision:\", precision_score(y_true, y_pred))\n",
    "print(\"Recall (sensitivity):\", recall_score(y_true, y_pred))\n",
    "print(\"AUC:\", roc_auc_score(y_true, y_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "926e6446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 751ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 412ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 451ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 428ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 350ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 403ms/step\n",
      "Num labels:      191\n",
      "Num predictions: 191\n",
      "Num probabilities: 191\n",
      "Accuracy:    0.8481675392670157\n",
      "Precision:   0.0\n",
      "Recall:      0.0\n",
      "AUC:         0.17369093231162194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\91951\\Downloads\\Lungs-Cancer-Detection-main\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# 1) Initialize as empty Python lists\n",
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "y_prob_list = []\n",
    "\n",
    "# 2) Loop once over your dataset, extending both lists equally\n",
    "for imgs, labels in test_ds:\n",
    "    # Predict cancer probability → shape (batch,1), then squeeze to (batch,)\n",
    "    probs = model.predict(imgs).squeeze(axis=1)\n",
    "    # Binary predictions\n",
    "    preds = (probs >= 0.5).astype(int)\n",
    "\n",
    "    # Convert labels and preds to Python lists, then extend\n",
    "    y_true_list.extend(labels.numpy().tolist())\n",
    "    y_pred_list.extend(preds.tolist())\n",
    "    y_prob_list.extend(probs.tolist())\n",
    "\n",
    "# 3) Debug: print lengths to verify match\n",
    "print(f\"Num labels:      {len(y_true_list)}\")\n",
    "print(f\"Num predictions: {len(y_pred_list)}\")\n",
    "print(f\"Num probabilities: {len(y_prob_list)}\")\n",
    "assert len(y_true_list) == len(y_pred_list) == len(y_prob_list), \"Counts don’t match!\"\n",
    "\n",
    "# 4) Convert to NumPy arrays\n",
    "y_true = np.array(y_true_list)\n",
    "y_pred = np.array(y_pred_list)\n",
    "y_prob = np.array(y_prob_list)\n",
    "\n",
    "# 5) Compute metrics\n",
    "print(\"Accuracy:   \", accuracy_score(y_true, y_pred))\n",
    "print(\"Precision:  \", precision_score(y_true, y_pred))\n",
    "print(\"Recall:     \", recall_score(y_true, y_pred))\n",
    "print(\"AUC:        \", roc_auc_score(y_true, y_prob))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44394125",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
